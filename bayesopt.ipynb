{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "# Training data is 11 points in [0,1] inclusive regularly spaced\n",
    "train_x = Variable(torch.linspace(0, 1, 11))\n",
    "# True function is sin(2*pi*x) with Gaussian noise N(0,0.04)\n",
    "train_y = Variable(torch.sin(train_x.data * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2)\n",
    "\n",
    "from torch import optim\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        # Our mean function is constant in the interval [-1,1]\n",
    "        self.mean_module = ConstantMean(constant_bounds=(-1, 1))\n",
    "        # We use the RBF kernel as a universal approximator\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 5))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        # Return moddl output as GaussianRandomVariable\n",
    "        return GaussianRandomVariable(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptation of acquisition maximization from Python BayesOpt implementation found at\n",
    "#https://github.com/fmfn/BayesianOptimization\n",
    "\n",
    "def acq_max(ac, gp, y_max, bounds, random_state, n_warmup=1000, n_iter=250):\n",
    "    \"\"\"\n",
    "    A function to find the maximum of the acquisition function\n",
    "    It uses a combination of random sampling (cheap) and the 'L-BFGS-B'\n",
    "    optimization method. First by sampling `n_warmup` (1e5) points at random,\n",
    "    and then running L-BFGS-B from `n_iter` (250) random starting points.\n",
    "    Parameters\n",
    "    ----------\n",
    "    :param ac:\n",
    "        The acquisition function object that return its point-wise value.\n",
    "    :param gp:\n",
    "        A gaussian process fitted to the relevant data.\n",
    "    :param y_max:\n",
    "        The current maximum known value of the target function.\n",
    "    :param bounds:\n",
    "        The variables bounds to limit the search of the acq max.\n",
    "    :param random_state:\n",
    "        instance of np.RandomState random number generator\n",
    "    :param n_warmup:\n",
    "        number of times to randomly sample the aquisition function\n",
    "    :param n_iter:\n",
    "        number of times to run scipy.minimize\n",
    "    Returns\n",
    "    -------\n",
    "    :return: x_max, The arg max of the acquisition function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Warm up with random points\n",
    "    x_tries = Variable(torch.linspace(bounds[0][0], bounds[0][1], n_warmup))\n",
    "    \n",
    "    ys = ac(x_tries, gp, y_max, xi=0.2).data.numpy()\n",
    "    x_max = x_tries.data.numpy()[ys.argmax()]\n",
    "    max_acq = float(ys.max())\n",
    "\n",
    "    # Explore the parameter space more throughly\n",
    "    x_seeds = Variable(torch.linspace(bounds[0][0], bounds[0][1], n_iter))\n",
    "    \n",
    "    for x_try in x_seeds:\n",
    "\n",
    "        # Find the minimum of minus the acquisition function\n",
    "        res = minimize(lambda x: -ac(Variable(torch.from_numpy(x).float()), gp, y_max, xi=0.2),\n",
    "                       x_try,\n",
    "                       bounds=bounds,\n",
    "                       method=\"L-BFGS-B\")\n",
    "\n",
    "        # See if success\n",
    "        if not res.success:\n",
    "            continue\n",
    "           \n",
    "        # Store it if better than previous minimum(maximum).\n",
    "        if max_acq is None or float((-res.fun[0]).gt(max_acq)):\n",
    "            x_max = res.x\n",
    "            max_acq = float(-res.fun[0])\n",
    "\n",
    "    # Clip output to make sure it lies within the bounds. Due to floating\n",
    "    # point technicalities this is not always the case.\n",
    "    return np.clip(x_max, bounds[0][0], bounds[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayes_opt:\n",
    "    \n",
    "    def __init__(self, func, step_num):\n",
    "        \n",
    "        self.step_num = step_num\n",
    "        self.sample_pts = Variable(torch.zeros(step_num))     \n",
    "        self.sample_vals = Variable(torch.zeros(step_num))       \n",
    "        self.opt_val = -float(\"inf\")       \n",
    "        self.opt_soln = None       \n",
    "        self.obj_func = func\n",
    "        self.model_GP = None\n",
    "        \n",
    "        \n",
    "    def _ei(self, x, gp, y_max, xi):\n",
    " \n",
    "        predict_pt = gp(x)\n",
    "        mean = predict_pt.mean()\n",
    "        std = torch.sqrt(predict_pt.var())\n",
    "        z = (mean - y_max - xi)/std\n",
    "    \n",
    "        return (\n",
    "            (mean - y_max - xi) * Variable(torch.from_numpy(norm.cdf(z.data)).float()) + \n",
    "            std * Variable(torch.from_numpy(norm.pdf(z.data)).float())\n",
    "            )        \n",
    "    \n",
    "    def _update_GP(self, train_x, train_y):\n",
    "        \n",
    "        likelihood = GaussianLikelihood(log_noise_bounds=(-5, 5))\n",
    "        \n",
    "        model = ExactGPModel(train_x.data, train_y.data, likelihood)\n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "        \n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam([\n",
    "            {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "        ], lr=0.1)\n",
    "\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        training_iter = 50\n",
    "        for i in range(training_iter):\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Output from model\n",
    "            output = model(train_x)\n",
    "            # Calc loss and backprop gradients\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()\n",
    "            #print('Iter %d/%d - Loss: %.3f   log_lengthscale: %.3f   log_noise: %.3f' % (\n",
    "                #i + 1, training_iter, loss.data[0],\n",
    "                #model.covar_module.log_lengthscale.data[0, 0],\n",
    "                #model.likelihood.log_noise.data[0]\n",
    "            #))\n",
    "            optimizer.step()\n",
    "    \n",
    "        # Put model and likelihood into eval mode\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def optimize(self):\n",
    "        \n",
    "        start_pts = Variable(torch.rand(3))\n",
    "        start_vals = Variable(start_pts.data.apply_(self.obj_func))\n",
    "        self.opt_val = torch.min(start_vals.data)\n",
    "        ind = torch.min(start_vals.data, 0)[1]\n",
    "        self.opt_soln = start_pts[ind]\n",
    "\n",
    "        self.model_GP = self._update_GP(start_pts, start_vals)\n",
    "        \n",
    "        print(\"GP initiated\")\n",
    "        \n",
    "        for t in range(self.step_num):\n",
    "            \n",
    "            if t%10 == 9: print(t, ': ', self.opt_val)\n",
    "            \n",
    "            new_pt = acq_max(ac=self._ei, gp=self.model_GP, y_max=self.opt_val, bounds=[(0, 1)], random_state=np.random.RandomState())\n",
    "            new_val = self.obj_func(new_pt)\n",
    "            self.sample_pts[t] = float(new_pt)\n",
    "            self.sample_vals[t] = float(new_val)\n",
    "            \n",
    "            if new_val > self.opt_val:\n",
    "                self.opt_val = new_val \n",
    "                self.opt_soln = new_pt\n",
    "                \n",
    "            self.model_GP = self._update_GP(self.sample_pts[:t+1], self.sample_vals[:t+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP initiated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The input matches the stored training data. Did you forget to call model.train()?\n",
      "WARNING:root:The input matches the stored training data. Did you forget to call model.train()?\n",
      "WARNING:root:The input matches the stored training data. Did you forget to call model.train()?\n",
      "WARNING:root:The input matches the stored training data. Did you forget to call model.train()?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 :  -0.5\n",
      "19 :  0.6701980146984186\n"
     ]
    }
   ],
   "source": [
    "#test _update_GP\n",
    "\n",
    "def test_func(x): \n",
    "    return -1/(x+1)*np.cos(2*math.pi*x)\n",
    "\n",
    "# Training data is 11 points in [0,1] inclusive regularly spaced\n",
    "#train_x = Variable(torch.linspace(0, 1, 11))\n",
    "train_x = Variable(torch.rand(11))\n",
    "# True function is sin(2*pi*x) with Gaussian noise N(0,0.04)\n",
    "train_y = Variable(torch.sin(train_x.data * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2)\n",
    "\n",
    "test = Bayes_opt(test_func, 20)\n",
    "\n",
    "test.optimize()\n",
    "\n",
    "\n",
    "\n",
    "#model = test._update_GP(x_np=train_x, y_np=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bayes_opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-758c3f8d8709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Plot the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0max_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_ax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Observed Values (Likelihood)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-164-758c3f8d8709>\u001b[0m in \u001b[0;36max_plot\u001b[0;34m(ax, rand_var, title)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0max_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mrand_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_GP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_pts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bayes_opt' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff75ea56b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put model and likelihood into eval mode\n",
    "model = test.model_GP\n",
    "likelihood = GaussianLikelihood(log_noise_bounds=(-5, 5))\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plot\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "# Test points are regularly spaced along [0,1] every 0.02\n",
    "test_x = Variable(torch.linspace(0, 1, 51))\n",
    "# Make predictions by feeding model through likelihood\n",
    "with gpytorch.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "# Define plotting function\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    \n",
    "    rand_var = bayes_opt.model_GP\n",
    "    train_x = bayes_opt.sample_pts\n",
    "    train_y = bayes_opt.sample_vals\n",
    "    \n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = rand_var.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    #Plot opt soln\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.data.numpy(), rand_var.mean().data.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.data.numpy(), lower.data.numpy(), upper.data.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "# Plot the predictions\n",
    "ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff75ebc2b38>]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff75ebc2a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_x = np.linspace(0, 1, 100)\n",
    "true_y = np.vectorize(test_func)(true_x)\n",
    "\n",
    "plt.scatter(test.sample_pts.data.numpy(), test.sample_vals.data.numpy())\n",
    "plt.plot(true_x, true_y, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sample_pts\n",
    "test.sample_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max = Variable(torch.Tensor([0]))\n",
    "xi = Variable(torch.Tensor([0.01]))\n",
    "#train_x = Variable(torch.Tensor([[0, 0], [0.5, 0.5], [1, 1]]))\n",
    "train_x = Variable(torch.linspace(0.1, 0.9,  3))\n",
    "train_y = Variable(torch.Tensor([0, 1 , 0]))\n",
    "\n",
    "\n",
    "def _ei(x, gp, y_max, xi):\n",
    "    \n",
    "    predict_pt = gp(x)\n",
    "    mean = predict_pt.mean()\n",
    "    std = torch.sqrt(predict_pt.var())\n",
    "    z = (mean - y_max - xi)/std\n",
    "    \n",
    "    return (\n",
    "            (mean - y_max - xi) * Variable(torch.from_numpy(norm.cdf(z.data)).float()) + \n",
    "            std * Variable(torch.from_numpy(norm.pdf(z.data)).float())\n",
    "        )\n",
    "\n",
    "testf = lambda x: x*(x-1)\n",
    "test = Bayes_opt(testf, 10)\n",
    "testGP = test._update_GP(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = Variable(torch.Tensor([0.2, 0.4, 0.6]), requires_grad=False)\n",
    "\n",
    "mask = test_x.gt(0.5).data\n",
    "test_x[mask] = Variable(torch.Tensor([0]))\n",
    "\n",
    "a = np.array(0)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_param_optimizer(x):\n",
    "    input_param = torch.nn.Parameter(x.data)\n",
    "    optimizer = optim.LBFGS([input_param])\n",
    "    return input_param, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.7417\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-57a371bbc0d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/gpytorch/lib/python3.6/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# evaluate initial f(x) and df/dx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0morig_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mcurrent_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-169-57a371bbc0d3>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0m_ei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestGP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/gpytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/gpytorch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/gpytorch/lib/python3.6/site-packages/gpytorch/utils/function_factory.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mderivative_quadratic_form_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mmatmul_closure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul_closure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "test_x = Variable(torch.Tensor([0.25, 0.75]), requires_grad=True).expand(1, 2)\n",
    "\n",
    "x, optimizer = get_input_param_optimizer(test_x)\n",
    "\n",
    "for t in range(5):\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = -_ei(x, testGP, y_max, xi)\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "        return loss\n",
    "    optimizer.step(closure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Acq_func(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        result, = ctx.saved_variables\n",
    "        return grad_output * result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.3455\n",
       " 0.3453\n",
       " 0.3451\n",
       " 0.3450\n",
       " 0.3448\n",
       " 0.3447\n",
       " 0.3445\n",
       " 0.3444\n",
       " 0.3442\n",
       " 0.3441\n",
       " 0.3440\n",
       " 0.3438\n",
       " 0.3437\n",
       " 0.3436\n",
       " 0.3435\n",
       " 0.3433\n",
       " 0.3432\n",
       " 0.3431\n",
       " 0.3430\n",
       " 0.3429\n",
       " 0.3428\n",
       " 0.3427\n",
       " 0.3426\n",
       " 0.3425\n",
       " 0.3424\n",
       " 0.3423\n",
       " 0.3423\n",
       " 0.3422\n",
       " 0.3421\n",
       " 0.3420\n",
       " 0.3420\n",
       " 0.3419\n",
       " 0.3418\n",
       " 0.3418\n",
       " 0.3417\n",
       " 0.3417\n",
       " 0.3416\n",
       " 0.3416\n",
       " 0.3416\n",
       " 0.3415\n",
       " 0.3415\n",
       " 0.3415\n",
       " 0.3414\n",
       " 0.3414\n",
       " 0.3414\n",
       " 0.3414\n",
       " 0.3414\n",
       " 0.3413\n",
       " 0.3413\n",
       " 0.3413\n",
       " 0.3413\n",
       " 0.3413\n",
       " 0.3413\n",
       " 0.3414\n",
       " 0.3414\n",
       " 0.3414\n",
       " 0.3414\n",
       " 0.3414\n",
       " 0.3415\n",
       " 0.3415\n",
       " 0.3415\n",
       " 0.3416\n",
       " 0.3416\n",
       " 0.3416\n",
       " 0.3417\n",
       " 0.3417\n",
       " 0.3418\n",
       " 0.3418\n",
       " 0.3419\n",
       " 0.3420\n",
       " 0.3420\n",
       " 0.3421\n",
       " 0.3422\n",
       " 0.3423\n",
       " 0.3423\n",
       " 0.3424\n",
       " 0.3425\n",
       " 0.3426\n",
       " 0.3427\n",
       " 0.3428\n",
       " 0.3429\n",
       " 0.3430\n",
       " 0.3431\n",
       " 0.3432\n",
       " 0.3433\n",
       " 0.3435\n",
       " 0.3436\n",
       " 0.3437\n",
       " 0.3438\n",
       " 0.3440\n",
       " 0.3441\n",
       " 0.3442\n",
       " 0.3444\n",
       " 0.3445\n",
       " 0.3447\n",
       " 0.3448\n",
       " 0.3450\n",
       " 0.3451\n",
       " 0.3453\n",
       " 0.3455\n",
       "[torch.FloatTensor of size 100]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = Variable(torch.linspace(0, 1, 100))\n",
    "\n",
    "_ei(test_x, testGP, y_max, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpytorch]",
   "language": "python",
   "name": "conda-env-gpytorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
