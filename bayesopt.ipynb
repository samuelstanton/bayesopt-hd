{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import test_functions\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "# Training data is 11 points in [0,1] inclusive regularly spaced\n",
    "train_x = Variable(torch.linspace(0, 1, 11))\n",
    "# True function is sin(2*pi*x) with Gaussian noise N(0,0.04)\n",
    "train_y = Variable(torch.sin(train_x.data * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2)\n",
    "\n",
    "from torch import optim\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        # Our mean function is constant in the interval [-1,1]\n",
    "        self.mean_module = ConstantMean(constant_bounds=(-1, 1))\n",
    "        # We use the RBF kernel as a universal approximator\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 5))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        # Return moddl output as GaussianRandomVariable\n",
    "        return GaussianRandomVariable(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptation of acquisition maximization from Python BayesOpt implementation found at\n",
    "#https://github.com/fmfn/BayesianOptimization\n",
    "\n",
    "def acq_max(ac, gp, y_max, dim, bounds, random_state, n_warmup=1000, n_iter=10):\n",
    "    \"\"\"\n",
    "    A function to find the maximum of the acquisition function\n",
    "    It uses a combination of random sampling (cheap) and the 'L-BFGS-B'\n",
    "    optimization method. First by sampling `n_warmup` (1e5) points at random,\n",
    "    and then running L-BFGS-B from `n_iter` (250) random starting points.\n",
    "    Parameters\n",
    "    ----------\n",
    "    :param ac:\n",
    "        The acquisition function object that return its point-wise value.\n",
    "    :param gp:\n",
    "        A gaussian process fitted to the relevant data.\n",
    "    :param y_max:\n",
    "        The current maximum known value of the target function.\n",
    "    :param bounds:\n",
    "        The variables bounds to limit the search of the acq max.\n",
    "    :param random_state:\n",
    "        instance of np.RandomState random number generator\n",
    "    :param n_warmup:\n",
    "        number of times to randomly sample the aquisition function\n",
    "    :param n_iter:\n",
    "        number of times to run scipy.minimize\n",
    "    Returns\n",
    "    -------\n",
    "    :return: x_max, The arg max of the acquisition function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Warm up with random points\n",
    "    #x_tries = Variable(torch.linspace(bounds[0][0], bounds[0][1], n_warmup))\n",
    "    \n",
    "    #ys = ac(x_tries, gp, y_max, xi=0.01).data.numpy()\n",
    "    #x_max = x_tries.data.numpy()[ys.argmax()]\n",
    "    #max_acq = float(ys.max())\n",
    "    \n",
    "    #Initialize\n",
    "    x_max = Variable(torch.Tensor(1, dim).uniform_(bounds[0][0], bounds[0][1]))\n",
    "    max_acq = ac(x_max, gp, y_max, xi=0.5)\n",
    "\n",
    "    # Explore the parameter space more throughly\n",
    "    x_seeds = Variable(torch.Tensor(n_iter*dim, dim).uniform_(bounds[0][0], bounds[0][1]))\n",
    "    \n",
    "    for x_try in x_seeds:\n",
    "        x_try = x_try.view(1, dim)\n",
    "\n",
    "        # Find the minimum of minus the acquisition function\n",
    "        res = minimize(lambda x: -ac(Variable(torch.from_numpy(x).float()).view(1, dim), gp, y_max, xi=0.5),\n",
    "                       x_try,\n",
    "                       bounds=bounds,\n",
    "                       method=\"L-BFGS-B\")\n",
    "\n",
    "        # See if success\n",
    "        if not res.success:\n",
    "            continue\n",
    "           \n",
    "        # Store it if better than previous minimum(maximum).\n",
    "        if max_acq is None or float((-res.fun[0]).gt(max_acq)):\n",
    "            x_max = Variable(torch.from_numpy(np.clip(res.x, bounds[0][0], bounds[0][1])).float()) \n",
    "            max_acq = float(-res.fun[0])\n",
    "\n",
    "    # Clip output to make sure it lies within the bounds. Due to floating\n",
    "    # point technicalities this is not always the case.\n",
    "    return x_max.view(1, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayes_opt:\n",
    "    \n",
    "    def __init__(self, func, dim, step_num):\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.bounds = [(0,1)]*dim\n",
    "        self.step_num = step_num    \n",
    "        self.obj_func = func\n",
    "        self.model_GP = None\n",
    "        \n",
    "        \n",
    "    def _ei(self, x, gp, y_max, xi):\n",
    " \n",
    "        predict_pt = gp(x)\n",
    "        mean = predict_pt.mean()\n",
    "        std = torch.sqrt(predict_pt.var())\n",
    "        z = (mean - y_max - xi)/std\n",
    "    \n",
    "        return (\n",
    "            (mean - y_max - xi) * Variable(torch.from_numpy(norm.cdf(z.data)).float()) + \n",
    "            std * Variable(torch.from_numpy(norm.pdf(z.data)).float())\n",
    "            )        \n",
    "    \n",
    "    def _update_GP(self, train_x, train_y):\n",
    "        \n",
    "        likelihood = GaussianLikelihood(log_noise_bounds=(-5, 5))\n",
    "        \n",
    "        model = ExactGPModel(train_x.data, train_y.data, likelihood)\n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "        \n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam([\n",
    "            {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "        ], lr=0.1)\n",
    "\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        training_iter = 50\n",
    "        for i in range(training_iter):\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Output from model\n",
    "            output = model(train_x)\n",
    "            # Calc loss and backprop gradients\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()\n",
    "            #print('Iter %d/%d - Loss: %.3f   log_lengthscale: %.3f   log_noise: %.3f' % (\n",
    "                #i + 1, training_iter, loss.data[0],\n",
    "                #model.covar_module.log_lengthscale.data[0, 0],\n",
    "                #model.likelihood.log_noise.data[0]\n",
    "            #))\n",
    "            optimizer.step()\n",
    "    \n",
    "        # Put model and likelihood into eval mode\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def optimize(self, mode=\"compact\"):\n",
    "        \n",
    "        #Allocate space for iterates, initialize algorithm\n",
    "        start_num = 2\n",
    "        self.sample_pts = Variable(torch.zeros(self.step_num, self.dim))     \n",
    "        self.sample_vals = Variable(torch.zeros(self.step_num))\n",
    "        start_pts = Variable(torch.rand(start_num, self.dim))\n",
    "        start_vals = self.obj_func(start_pts)\n",
    "        self.sample_pts[:start_num] = start_pts\n",
    "        self.sample_vals[:start_num] = start_vals\n",
    "        self.opt_val = torch.min(start_vals.data)\n",
    "        ind = torch.min(start_vals.data, 0)[1]\n",
    "        self.opt_soln = start_pts[ind]\n",
    "\n",
    "        self.model_GP = self._update_GP(start_pts, start_vals)\n",
    "        \n",
    "        if mode==\"eval\":\n",
    "            self.obj_hist = Variable(torch.zeros(step_num))\n",
    "            self.obj_hist[:start_num] = self.opt_val\n",
    "\n",
    "        print(\"GP initiated\")\n",
    "        \n",
    "        for t in range(start_num, self.step_num):\n",
    "            \n",
    "            if t%10 == 0: print(t, ': ', self.opt_val)\n",
    "            \n",
    "            #Get next point from acquisition function, evaluate objective\n",
    "            new_pt = acq_max(ac=self._ei, gp=self.model_GP, y_max=self.opt_val, \n",
    "                             dim=self.dim, bounds=self.bounds, random_state=np.random.RandomState())\n",
    "            new_val = float(self.obj_func(new_pt))\n",
    "            self.sample_pts[t] = new_pt\n",
    "            self.sample_vals[t] = new_val\n",
    "            \n",
    "            if new_val > self.opt_val:\n",
    "                self.opt_val = new_val\n",
    "                self.opt_soln = new_pt\n",
    "                \n",
    "            if mode==\"eval\":\n",
    "                self.obj_hist[t] = self.opt_val\n",
    "                \n",
    "            #Update GP with new observation\n",
    "            self.model_GP = self._update_GP(self.sample_pts[:t+1], self.sample_vals[:t+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP initiated\n",
      "10 :  2.4179000854492188\n",
      "20 :  2.4179000854492188\n",
      "30 :  2.4179000854492188\n",
      "40 :  2.4179000854492188\n",
      "50 :  2.4179000854492188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4179000854492188"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3f1830be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step_num = 60\n",
    "\n",
    "test = Bayes_opt(func=test_functions.hartmann6d, dim=6, step_num=step_num)\n",
    "\n",
    "test.optimize(mode=\"eval\")\n",
    "\n",
    "plt.plot(range(step_num), test.obj_hist.data.numpy())\n",
    "\n",
    "test.opt_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bayes_opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-758c3f8d8709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Plot the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0max_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_ax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Observed Values (Likelihood)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-164-758c3f8d8709>\u001b[0m in \u001b[0;36max_plot\u001b[0;34m(ax, rand_var, title)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0max_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mrand_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_GP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_pts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bayes_opt' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff75ea56b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put model and likelihood into eval mode\n",
    "model = test.model_GP\n",
    "likelihood = GaussianLikelihood(log_noise_bounds=(-5, 5))\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plot\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "# Test points are regularly spaced along [0,1] every 0.02\n",
    "test_x = Variable(torch.linspace(0, 1, 51))\n",
    "# Make predictions by feeding model through likelihood\n",
    "with gpytorch.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "# Define plotting function\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    \n",
    "    rand_var = bayes_opt.model_GP\n",
    "    train_x = bayes_opt.sample_pts\n",
    "    train_y = bayes_opt.sample_vals\n",
    "    \n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = rand_var.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    #Plot opt soln\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.data.numpy(), rand_var.mean().data.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.data.numpy(), lower.data.numpy(), upper.data.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "# Plot the predictions\n",
    "ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpytorch]",
   "language": "python",
   "name": "conda-env-gpytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
