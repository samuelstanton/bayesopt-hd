{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "# Training data is 11 points in [0,1] inclusive regularly spaced\n",
    "train_x = Variable(torch.linspace(0, 1, 11))\n",
    "# True function is sin(2*pi*x) with Gaussian noise N(0,0.04)\n",
    "train_y = Variable(torch.sin(train_x.data * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2)\n",
    "\n",
    "from torch import optim\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        # Our mean function is constant in the interval [-1,1]\n",
    "        self.mean_module = ConstantMean(constant_bounds=(-1, 1))\n",
    "        # We use the RBF kernel as a universal approximator\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 5))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        # Return moddl output as GaussianRandomVariable\n",
    "        return GaussianRandomVariable(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptation of acquisition maximization from Python BayesOpt implementation found at\n",
    "#https://github.com/fmfn/BayesianOptimization\n",
    "\n",
    "def acq_max(ac, gp, y_max, dim, bounds, random_state, n_warmup=1000, n_iter=250):\n",
    "    \"\"\"\n",
    "    A function to find the maximum of the acquisition function\n",
    "    It uses a combination of random sampling (cheap) and the 'L-BFGS-B'\n",
    "    optimization method. First by sampling `n_warmup` (1e5) points at random,\n",
    "    and then running L-BFGS-B from `n_iter` (250) random starting points.\n",
    "    Parameters\n",
    "    ----------\n",
    "    :param ac:\n",
    "        The acquisition function object that return its point-wise value.\n",
    "    :param gp:\n",
    "        A gaussian process fitted to the relevant data.\n",
    "    :param y_max:\n",
    "        The current maximum known value of the target function.\n",
    "    :param bounds:\n",
    "        The variables bounds to limit the search of the acq max.\n",
    "    :param random_state:\n",
    "        instance of np.RandomState random number generator\n",
    "    :param n_warmup:\n",
    "        number of times to randomly sample the aquisition function\n",
    "    :param n_iter:\n",
    "        number of times to run scipy.minimize\n",
    "    Returns\n",
    "    -------\n",
    "    :return: x_max, The arg max of the acquisition function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Warm up with random points\n",
    "    #x_tries = Variable(torch.linspace(bounds[0][0], bounds[0][1], n_warmup))\n",
    "    \n",
    "    #ys = ac(x_tries, gp, y_max, xi=0.01).data.numpy()\n",
    "    #x_max = x_tries.data.numpy()[ys.argmax()]\n",
    "    #max_acq = float(ys.max())\n",
    "    \n",
    "    #Initialize\n",
    "    x_max = Variable(torch.Tensor(1, dim).uniform_(bounds[0][0], bounds[0][1]))\n",
    "    max_acq = ac(x_max, gp, y_max, xi=0.01)\n",
    "\n",
    "    # Explore the parameter space more throughly\n",
    "    x_seeds = Variable(torch.Tensor(n_iter, dim).uniform_(bounds[0][0], bounds[0][1]))\n",
    "    \n",
    "    for x_try in x_seeds:\n",
    "        x_try = x_try.view(1, dim)\n",
    "\n",
    "        # Find the minimum of minus the acquisition function\n",
    "        res = minimize(lambda x: -ac(Variable(torch.from_numpy(x).float()).view(1, dim), gp, y_max, xi=0.01),\n",
    "                       x_try,\n",
    "                       bounds=bounds,\n",
    "                       method=\"L-BFGS-B\")\n",
    "\n",
    "        # See if success\n",
    "        if not res.success:\n",
    "            continue\n",
    "           \n",
    "        # Store it if better than previous minimum(maximum).\n",
    "        if max_acq is None or float((-res.fun[0]).gt(max_acq)):\n",
    "            x_max = Variable(torch.from_numpy(np.clip(res.x, bounds[0][0], bounds[0][1])).float()) \n",
    "            max_acq = float(-res.fun[0])\n",
    "\n",
    "    # Clip output to make sure it lies within the bounds. Due to floating\n",
    "    # point technicalities this is not always the case.\n",
    "    return x_max.view(1, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayes_opt:\n",
    "    \n",
    "    def __init__(self, func, dim, step_num):\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.bounds = [(0,1)]*dim\n",
    "        self.step_num = step_num\n",
    "        self.sample_pts = Variable(torch.zeros(step_num, dim))     \n",
    "        self.sample_vals = Variable(torch.zeros(step_num))       \n",
    "        self.opt_val = -float(\"inf\")       \n",
    "        self.opt_soln = None       \n",
    "        self.obj_func = func\n",
    "        self.model_GP = None\n",
    "        \n",
    "        \n",
    "    def _ei(self, x, gp, y_max, xi):\n",
    " \n",
    "        predict_pt = gp(x)\n",
    "        mean = predict_pt.mean()\n",
    "        std = torch.sqrt(predict_pt.var())\n",
    "        z = (mean - y_max - xi)/std\n",
    "    \n",
    "        return (\n",
    "            (mean - y_max - xi) * Variable(torch.from_numpy(norm.cdf(z.data)).float()) + \n",
    "            std * Variable(torch.from_numpy(norm.pdf(z.data)).float())\n",
    "            )        \n",
    "    \n",
    "    def _update_GP(self, train_x, train_y):\n",
    "        \n",
    "        likelihood = GaussianLikelihood(log_noise_bounds=(-5, 5))\n",
    "        \n",
    "        model = ExactGPModel(train_x.data, train_y.data, likelihood)\n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "        \n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam([\n",
    "            {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "        ], lr=0.1)\n",
    "\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        training_iter = 50\n",
    "        for i in range(training_iter):\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Output from model\n",
    "            output = model(train_x)\n",
    "            # Calc loss and backprop gradients\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()\n",
    "            #print('Iter %d/%d - Loss: %.3f   log_lengthscale: %.3f   log_noise: %.3f' % (\n",
    "                #i + 1, training_iter, loss.data[0],\n",
    "                #model.covar_module.log_lengthscale.data[0, 0],\n",
    "                #model.likelihood.log_noise.data[0]\n",
    "            #))\n",
    "            optimizer.step()\n",
    "    \n",
    "        # Put model and likelihood into eval mode\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def optimize(self):\n",
    "        \n",
    "        start_pts = Variable(torch.rand(3, self.dim))\n",
    "        start_vals = self.obj_func(start_pts)\n",
    "        self.opt_val = torch.min(start_vals.data)\n",
    "        ind = torch.min(start_vals.data, 0)[1]\n",
    "        self.opt_soln = start_pts[ind]\n",
    "\n",
    "        self.model_GP = self._update_GP(start_pts, start_vals)\n",
    "        \n",
    "        print(\"GP initiated\")\n",
    "        \n",
    "        for t in range(self.step_num):\n",
    "            \n",
    "            if t%10 == 0: print(t, ': ', self.opt_val)\n",
    "            \n",
    "            new_pt = acq_max(ac=self._ei, gp=self.model_GP, y_max=self.opt_val, \n",
    "                             dim=self.dim, bounds=self.bounds, random_state=np.random.RandomState())\n",
    "            new_val = float(self.obj_func(new_pt))\n",
    "            self.sample_pts[t] = new_pt\n",
    "            self.sample_vals[t] = new_val\n",
    "            \n",
    "            if new_val > self.opt_val:\n",
    "                self.opt_val = new_val\n",
    "                self.opt_soln = new_pt\n",
    "                \n",
    "            self.model_GP = self._update_GP(self.sample_pts[:t+1], self.sample_vals[:t+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP initiated\n",
      "0 :  0.05697297677397728\n"
     ]
    }
   ],
   "source": [
    "#def test_func(x): \n",
    "#    return -1/(x+1)*np.cos(2*math.pi*x)\n",
    "\n",
    "def test_func(x):\n",
    "    n = x.shape[-1]\n",
    "    if len(x.shape) == 1:\n",
    "        x = x.view(1, n)\n",
    "    val = Variable(torch.zeros(x.shape[0]))\n",
    "    for i in range(n):\n",
    "        val = val + -1/(x[:, i]+1)*torch.cos(2*math.pi*x[:, i])\n",
    "    return val\n",
    "\n",
    "step_num = 10\n",
    "\n",
    "test = Bayes_opt(func=test_func, dim=2, step_num=step_num)\n",
    "\n",
    "test.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05697297677397728"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1993898b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#true_x = np.linspace(0, 1, 100)\n",
    "#true_y = np.vectorize(test_func)(true_x)\n",
    "#print((test.opt_val-true_y.max())**2)\n",
    "step_num = 10\n",
    "plt.scatter(range(step_num), test.sample_vals.data.numpy())\n",
    "#plt.plot(true_x, true_y, 'r')\n",
    "test.opt_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bayes_opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-758c3f8d8709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Plot the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0max_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_ax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Observed Values (Likelihood)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-164-758c3f8d8709>\u001b[0m in \u001b[0;36max_plot\u001b[0;34m(ax, rand_var, title)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0max_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mrand_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_GP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_pts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bayes_opt' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff75ea56b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put model and likelihood into eval mode\n",
    "model = test.model_GP\n",
    "likelihood = GaussianLikelihood(log_noise_bounds=(-5, 5))\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plot\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "# Test points are regularly spaced along [0,1] every 0.02\n",
    "test_x = Variable(torch.linspace(0, 1, 51))\n",
    "# Make predictions by feeding model through likelihood\n",
    "with gpytorch.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "# Define plotting function\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    \n",
    "    rand_var = bayes_opt.model_GP\n",
    "    train_x = bayes_opt.sample_pts\n",
    "    train_y = bayes_opt.sample_vals\n",
    "    \n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = rand_var.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    #Plot opt soln\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.data.numpy(), rand_var.mean().data.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.data.numpy(), lower.data.numpy(), upper.data.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "# Plot the predictions\n",
    "ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpytorch]",
   "language": "python",
   "name": "conda-env-gpytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
